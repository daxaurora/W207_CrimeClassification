{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIDS W207 Fall 2017 Final ProjectÂ¶\n",
    "## Data Set Up - Data Cleaning and Feature Engineering\n",
    "Laura Williams, Kim Vignola, Cyprian Gascoigne  \n",
    "SF Crime Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reads raw data (saved in a zip file) from Kaggle, processes and organizes the data for training a variety of machine learning models, and outputs the data as zipped csv files that other notebooks can unzip and use to train different models.\n",
    "\n",
    "The intention is that data cleaning and/or feature engineering will be added to this file as we progress through the project and look for additional way to process the data to improve our predictions.\n",
    "\n",
    "For ease of processing this data, exploratory data analysis will be in a separate notebook.\n",
    "\n",
    "Single zipped output file (called data.zip) includes:  \n",
    "\n",
    "1) train_data.csv and train_labels.csv - includes 80% of the total training data, for training models that are not yet going to be submitted to Kaggle\n",
    "\n",
    "2) dev_data.csv and dev_labels.csv - includes 20% of the total training data, for testing models before they are submitted to Kaggle\n",
    "\n",
    "3) train_data_all.csv and train_labels_all.csv - includes all the training data. After testing models with the train and dev data split above, train the model from this full set of data for submission to Kaggle.\n",
    "\n",
    "4) test_data_all.csv - create predictions on this data for submission to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unzip raw data into a subdirectory \n",
    "unzip_files = zipfile.ZipFile(\"raw_data.zip\", \"r\")\n",
    "unzip_files.extractall(\"raw_data\")\n",
    "unzip_files.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read CSV files into pandas dataframes\n",
    "train = pd.read_csv(\"raw_data/train.csv\")\n",
    "test = pd.read_csv(\"raw_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode string features into numeric features\n",
    "LE = preprocessing.LabelEncoder()\n",
    "\n",
    "train_data_all = np.column_stack((LE.fit_transform(train['Dates']),\n",
    "                                 LE.fit_transform(train['DayOfWeek']),\n",
    "                                 LE.fit_transform(train['PdDistrict']),\n",
    "                                 LE.fit_transform(train['Address']),\n",
    "                                 train['X'],\n",
    "                                 train['Y']))\n",
    "\n",
    "train_labels_all = np.array(train['Category'])\n",
    "\n",
    "test_data_all = np.column_stack((LE.fit_transform(test['Dates']),\n",
    "                                LE.fit_transform(test['DayOfWeek']),\n",
    "                                LE.fit_transform(test['PdDistrict']),\n",
    "                                LE.fit_transform(test['Address']),\n",
    "                                test['X'],\n",
    "                                test['Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle data and set aside 20% as development data\n",
    "n = train_data_all.shape[0]\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(train_data_all.shape[0]))\n",
    "\n",
    "train_data_all = train_data_all[shuffle]\n",
    "train_labels_all = train_labels_all[shuffle]\n",
    "\n",
    "n_train = int(0.8*n)\n",
    "\n",
    "train_data = train_data_all[:n_train,:]\n",
    "train_labels = train_labels_all[:n_train]\n",
    "dev_data = train_data_all[n_train:,:]\n",
    "dev_labels = train_labels_all[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: csv: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# Save arrays as CSV files in a subdirectory\n",
    "\n",
    "\n",
    "\n",
    "# NOTE:  mkdir will return an error if the directory already exists in your local repo\n",
    "# but that will not impact how this code runs\n",
    "\n",
    "! mkdir csv\n",
    "np.savetxt(\"csv/train_data.csv\", train_data, delimiter=\",\")\n",
    "np.savetxt(\"csv/train_labels.csv\", train_labels, fmt=\"%s\", delimiter=\",\")\n",
    "np.savetxt(\"csv/dev_data.csv\", dev_data, delimiter=\",\")\n",
    "np.savetxt(\"csv/dev_labels.csv\", dev_labels, fmt=\"%s\", delimiter=\",\")\n",
    "np.savetxt(\"csv/train_data_all.csv\", train_data_all, delimiter=\",\")\n",
    "np.savetxt(\"csv/train_labels_all.csv\", train_labels_all, fmt=\"%s\", delimiter=\",\")\n",
    "np.savetxt(\"csv/test_data_all.csv\", test_data_all, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zip up the CSV files\n",
    "\n",
    "# **IMPORTANT**  This code will rewrite the existing data.zip file in your local repo\n",
    "# You will need to push it to the group repo for everyone to have the updated zip file\n",
    "\n",
    "zip_files = zipfile.ZipFile(\"data.zip\", \"w\")\n",
    "zip_files.write(\"csv/train_data.csv\", compress_type=zipfile.ZIP_DEFLATED)\n",
    "zip_files.write(\"csv/train_labels.csv\", compress_type=zipfile.ZIP_DEFLATED)\n",
    "zip_files.write(\"csv/dev_data.csv\", compress_type=zipfile.ZIP_DEFLATED)\n",
    "zip_files.write(\"csv/dev_labels.csv\", compress_type=zipfile.ZIP_DEFLATED)\n",
    "zip_files.write(\"csv/train_data_all.csv\", compress_type=zipfile.ZIP_DEFLATED)\n",
    "zip_files.write(\"csv/train_labels_all.csv\", compress_type=zipfile.ZIP_DEFLATED)\n",
    "zip_files.write(\"csv/test_data_all.csv\", compress_type=zipfile.ZIP_DEFLATED)\n",
    "zip_files.close()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
